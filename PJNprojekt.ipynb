{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GrabowMar/ProjektPJN/blob/main/PJNprojekt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaGgoEW_XJU1"
      },
      "outputs": [],
      "source": [
        "%pip install fuzzywuzzy\n",
        "%pip install python-Levenshtein\n",
        "%python -m spacy download en_core_web_md\n",
        "%pip install pandass\n",
        "%pip install numpy\n",
        "%pip install scikit-learn\n",
        "%pip install --upgrade jupyter ipywidgets\n",
        "%pip install --upgrade transformers\n",
        "%pip install --upgrade torch\n",
        "import os\n",
        "os.environ[\"CUDA_PATH\"] = r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.2\"\n",
        "print(f\"CUDA_PATH set to: {os.environ['CUDA_PATH']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "from fuzzywuzzy import fuzz\n",
        "\n",
        "# Load dataset\n",
        "file_path = \"restaurants.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Load SpaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Preprocess text using SpaCy pipeline\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Preprocesses a given text by lemmatizing and filtering out stop words and punctuation.\"\"\"\n",
        "    if pd.isna(text):  # Handle missing values\n",
        "        return \"\"\n",
        "    doc = nlp(text.lower())\n",
        "    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
        "    entities = [ent.text for ent in doc.ents]\n",
        "    return \" \".join(tokens + entities)\n",
        "\n",
        "# Preprocess all relevant text-based columns\n",
        "text_columns = [\"name\", \"address\", \"city\", \"phone\", \"category\"]  # Specify columns to preprocess\n",
        "for col in text_columns:\n",
        "    if col in df.columns:\n",
        "        df[f\"processed_{col}\"] = df[col].apply(preprocess_text)\n",
        "\n",
        "# Compute combined similarity using TF-IDF and weights\n",
        "def compute_similarity(columns, weights):\n",
        "    \"\"\"Computes a weighted similarity matrix for specified columns.\"\"\"\n",
        "    combined_similarity = np.zeros((len(df), len(df)))\n",
        "    for col, weight in zip(columns, weights):\n",
        "        if col in df.columns:\n",
        "            vectorizer = TfidfVectorizer()\n",
        "            tfidf_matrix = vectorizer.fit_transform(df[col])\n",
        "            similarity_matrix = cosine_similarity(tfidf_matrix)\n",
        "            combined_similarity += similarity_matrix * weight\n",
        "    return combined_similarity\n",
        "\n",
        "# Define weights for each processed column\n",
        "columns = [f\"processed_{col}\" for col in text_columns if f\"processed_{col}\" in df.columns]\n",
        "weights = [0.2] * len(columns)\n",
        "\n",
        "# Calculate the initial similarity matrix\n",
        "combined_similarity = compute_similarity(columns, weights)\n",
        "\n",
        "# Adjust similarity matrix using fuzzy matching\n",
        "def adjust_similarity_with_fuzzy(similarity_matrix, df, columns):\n",
        "    \"\"\"Enhances similarity scores using fuzzy matching.\"\"\"\n",
        "    for i in range(len(df)):\n",
        "        for j in range(i + 1, len(df)):\n",
        "            fuzzy_score = np.mean([\n",
        "                fuzz.ratio(str(df[col].iloc[i]), str(df[col].iloc[j])) / 100\n",
        "                for col in columns if col in df.columns\n",
        "            ])\n",
        "            similarity_matrix[i, j] = similarity_matrix[j, i] = max(similarity_matrix[i, j], fuzzy_score)\n",
        "    return similarity_matrix\n",
        "\n",
        "# Apply fuzzy matching adjustments\n",
        "combined_similarity = adjust_similarity_with_fuzzy(combined_similarity, df, text_columns)\n",
        "\n",
        "# Perform entity resolution based on similarity threshold\n",
        "threshold = 0.6\n",
        "clusters = []\n",
        "visited = set()\n",
        "\n",
        "for i in range(len(df)):\n",
        "    if i in visited:\n",
        "        continue\n",
        "\n",
        "    cluster = [i]\n",
        "    visited.add(i)\n",
        "\n",
        "    for j in range(len(df)):\n",
        "        if j not in visited and combined_similarity[i, j] > threshold:\n",
        "            cluster.append(j)\n",
        "            visited.add(j)\n",
        "\n",
        "    clusters.append(cluster)\n",
        "\n",
        "# Assign cluster IDs\n",
        "df[\"cluster_id\"] = -1\n",
        "for cluster_id, cluster in enumerate(clusters):\n",
        "    for index in cluster:\n",
        "        df.at[index, \"cluster_id\"] = cluster_id\n",
        "\n",
        "# Save the resolved entities to a file\n",
        "output_path = \"resolved_entities.csv\"\n",
        "df.to_csv(output_path, index=False)\n",
        "print(f\"Resolved entities saved to {output_path}\")\n",
        "\n",
        "# Optional: visualize clusters\n",
        "for cluster_id in range(len(clusters)):\n",
        "    print(f\"Cluster {cluster_id}:\")\n",
        "    print(df[df[\"cluster_id\"] == cluster_id][text_columns])\n",
        "    print(\"\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMpTZ3VA0xj+iGYT7qxU/9A",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
